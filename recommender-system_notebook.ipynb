{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Content-Based Recommender System for Movies: An End-To-End Project\n","\n","by [Sumit Pokharel](https://github.com/psumitcode), Ritsumeikan Asia Pacific University (last updated: Jan 5, 2023)\n","\n","**Objective**: To build a recommender system that can recommend 5 similar movies when a user picks 1 movie from the database.\n","\n","The dataset I've made use of is the [tmdb-movie-dataset](https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata), taken from Kaggle.\n","\n","The final product is a website that can be accessed [via this link](https://cine-recs.com/). More details on [the deployment](#5-deployment) section.\n","\n","## Table of Contents\n","- [1. Preprocessing](#1-preprocessing)\n","\n","    - [1.1 Importing the data and merging](#1.1-importing-the-data-and-merging)\n","    - [1.2 Feature extraction](#1.2-feature-extraction)\n","    - [1.3 Completing the feature extraction: 3 steps](#1.3-completing-the-feature-extraction-3-steps)\n","        - [Step 1: Getting rid of duplicate and missing data](#step-1-getting-rid-of-duplicate-and-missing-data)\n","        - [Step 2: Converting some columns into better formats](#step-2-converting-some-columns-into-better-formats)\n","        - [Step 3: Building a new dataframe from the dataframe above](#step-3-building-a-new-dataframe-from-the-dataframe-above)\n","<!-- Blank line -->\n","- [2. Text Vectorization](#2-text-vectorization)\n","\n","- [3. Creating the Main Function for Recommendation](#3-creating-the-main-function-for-recommendation)\n","\n","- [4. Streamlit and Deployment](#4-streamlit-and-deployment)\n","\n","**Keywords:** text vectorization, panda, numpy, scikit-learn, nltk, streamlit, pickle, render"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a name=\"1\"></a>\n","## 1. Preprocessing"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a name=\"1.1\"></a>\n","### 1.1 Importing the data and merging"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-10-02T11:17:16.457293Z","iopub.status.busy":"2022-10-02T11:17:16.456857Z","iopub.status.idle":"2022-10-02T11:17:16.463436Z","shell.execute_reply":"2022-10-02T11:17:16.462250Z","shell.execute_reply.started":"2022-10-02T11:17:16.457257Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:16.474827Z","iopub.status.busy":"2022-10-02T11:17:16.474382Z","iopub.status.idle":"2022-10-02T11:17:16.978894Z","shell.execute_reply":"2022-10-02T11:17:16.977566Z","shell.execute_reply.started":"2022-10-02T11:17:16.474790Z"},"trusted":true},"outputs":[],"source":["movies = pd.read_csv(\"../input/tmdb-movie-metadata/tmdb_5000_movies.csv\")\n","credits = pd.read_csv(\"../input/tmdb-movie-metadata/tmdb_5000_credits.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:16.981598Z","iopub.status.busy":"2022-10-02T11:17:16.981118Z","iopub.status.idle":"2022-10-02T11:17:17.007763Z","shell.execute_reply":"2022-10-02T11:17:17.006223Z","shell.execute_reply.started":"2022-10-02T11:17:16.981557Z"},"trusted":true},"outputs":[],"source":["movies.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:17.009926Z","iopub.status.busy":"2022-10-02T11:17:17.009453Z","iopub.status.idle":"2022-10-02T11:17:17.029589Z","shell.execute_reply":"2022-10-02T11:17:17.028313Z","shell.execute_reply.started":"2022-10-02T11:17:17.009886Z"},"trusted":true},"outputs":[],"source":["credits.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:17.033705Z","iopub.status.busy":"2022-10-02T11:17:17.032871Z","iopub.status.idle":"2022-10-02T11:17:17.059409Z","shell.execute_reply":"2022-10-02T11:17:17.058267Z","shell.execute_reply.started":"2022-10-02T11:17:17.033650Z"},"trusted":true},"outputs":[],"source":["movies = movies.merge(credits, on = \"title\")\n","# Merging the two csv files"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:17.061551Z","iopub.status.busy":"2022-10-02T11:17:17.061096Z","iopub.status.idle":"2022-10-02T11:17:17.093550Z","shell.execute_reply":"2022-10-02T11:17:17.092541Z","shell.execute_reply.started":"2022-10-02T11:17:17.061504Z"},"trusted":true},"outputs":[],"source":["movies.head()\n","#how it looks after combining two csv files"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:17.095101Z","iopub.status.busy":"2022-10-02T11:17:17.094751Z","iopub.status.idle":"2022-10-02T11:17:17.123221Z","shell.execute_reply":"2022-10-02T11:17:17.121996Z","shell.execute_reply.started":"2022-10-02T11:17:17.095069Z"},"trusted":true},"outputs":[],"source":["movies.info()"]},{"attachments":{},"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2022-10-01T16:37:25.486899Z","iopub.status.busy":"2022-10-01T16:37:25.486291Z","iopub.status.idle":"2022-10-01T16:37:25.491914Z","shell.execute_reply":"2022-10-01T16:37:25.490879Z","shell.execute_reply.started":"2022-10-01T16:37:25.486855Z"}},"source":["<a name=\"1.2\"></a>\n","### 1.2 Feature extraction\n","\n","**Some unnecessary columns include:**\n","* `budget`\n","* `homepage`\n","* `original_language` may not be very useful in this scenario because the languages are mostly dominated by English and the others are scarcely distributed. Better to avoid this for this project.\n","* `original_title`\n","* `popularity` could be important but not for this project. \n","* `production_countries`\n","* `release_date` might want to think about how to incorporate this after I'm done with the project. But for now, I'll skip this.\n","* `revenue`\n","* `runtime`\n","* `spoken_languages`\n","* `status`\n","* `tagline` this is vague. Overview is better, so I'm keeping that instead of this.\n","* `vote_average`\n","* `vote_count`\n","* `movie_id`\n","\n","**On the other hand, some important columns are:**\n","* `genres`\n","* `id`\n","* `keywords`\n","* `title`\n","* `overview` for content similarity\n","* `cast`\n","* `crew`"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:17.125360Z","iopub.status.busy":"2022-10-02T11:17:17.124997Z","iopub.status.idle":"2022-10-02T11:17:17.149053Z","shell.execute_reply":"2022-10-02T11:17:17.147237Z","shell.execute_reply.started":"2022-10-02T11:17:17.125327Z"},"trusted":true},"outputs":[],"source":["movies = movies[[\"id\", \"title\", \"genres\", \"cast\", \"overview\", \"keywords\", \"crew\"]]\n","movies.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a name=\"1.3\"></a>\n","### 1.3 Completing the feature extraction: 3 steps\n","\n","1. Get rid of duplicate and missing data.\n","\n","2. Convert some columns into better formats.\n","\n","3. Build a new dataframe from the dataframe above. The dataframe will have:\n","1. `id`\n","2. `title`\n","3. `tags` *\n","\n","*`tags` will be made by merging `genres`, `cast`, `overview`, `keywords`, and `crew`.\n","\n","* From `cast`, we'll extract only the top 3 cast names.\n","\n","* From `crew`, we'll extract only the name of the director."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a name=\"1.3.1\"></a>\n","#### Step 1: Getting rid of duplicate and missing data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:17.153430Z","iopub.status.busy":"2022-10-02T11:17:17.152993Z","iopub.status.idle":"2022-10-02T11:17:17.170205Z","shell.execute_reply":"2022-10-02T11:17:17.168878Z","shell.execute_reply.started":"2022-10-02T11:17:17.153393Z"},"trusted":true},"outputs":[],"source":["# step 1a: getting rid of missing data\n","movies.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:17.172554Z","iopub.status.busy":"2022-10-02T11:17:17.172031Z","iopub.status.idle":"2022-10-02T11:17:17.186650Z","shell.execute_reply":"2022-10-02T11:17:17.185127Z","shell.execute_reply.started":"2022-10-02T11:17:17.172504Z"},"trusted":true},"outputs":[],"source":["movies.dropna(inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:17.192634Z","iopub.status.busy":"2022-10-02T11:17:17.192209Z","iopub.status.idle":"2022-10-02T11:17:17.301709Z","shell.execute_reply":"2022-10-02T11:17:17.300399Z","shell.execute_reply.started":"2022-10-02T11:17:17.192580Z"},"trusted":true},"outputs":[],"source":["#step1b: getting rid of duplicate data\n","movies.duplicated().sum()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["*No duplicate values, so we're done with step 1.*"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a name=\"1.3.2\"></a>\n","#### Step 2: Converting some columns into better formats\n","\n","We will convert the columns `genres`, `cast`, `overview`, `keywords`, and `crew` into better formats."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-03T05:59:15.378649Z","iopub.status.busy":"2022-10-03T05:59:15.378166Z","iopub.status.idle":"2022-10-03T05:59:15.470837Z","shell.execute_reply":"2022-10-03T05:59:15.469272Z","shell.execute_reply.started":"2022-10-03T05:59:15.378557Z"},"trusted":true},"outputs":[],"source":["movies.iloc[0].genres"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:17.311904Z","iopub.status.busy":"2022-10-02T11:17:17.311495Z","iopub.status.idle":"2022-10-02T11:17:17.325062Z","shell.execute_reply":"2022-10-02T11:17:17.323547Z","shell.execute_reply.started":"2022-10-02T11:17:17.311852Z"},"trusted":true},"outputs":[],"source":["import ast\n","def convert(obj):\n","    L = []\n","    for i in ast.literal_eval(obj): #ast.literal_eval used since only integers are accepted as string indices\n","        L.append(i[\"name\"])\n","    return L;"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:17.327745Z","iopub.status.busy":"2022-10-02T11:17:17.326955Z","iopub.status.idle":"2022-10-02T11:17:17.923680Z","shell.execute_reply":"2022-10-02T11:17:17.922782Z","shell.execute_reply.started":"2022-10-02T11:17:17.327693Z"},"trusted":true},"outputs":[],"source":["#for genres and keywords\n","movies['genres'] = movies['genres'].apply(convert)\n","movies['keywords'] = movies['keywords'].apply(convert)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:17.926242Z","iopub.status.busy":"2022-10-02T11:17:17.925033Z","iopub.status.idle":"2022-10-02T11:17:17.933181Z","shell.execute_reply":"2022-10-02T11:17:17.931891Z","shell.execute_reply.started":"2022-10-02T11:17:17.926197Z"},"trusted":true},"outputs":[],"source":["# I want to collect only top 3 cast names, so I'll stop before the counter hits 3.\n","def convert1(obj):\n","    L = []\n","    counter = 0\n","    for i in ast.literal_eval(obj):\n","        if counter < 3:\n","            L.append(i[\"name\"])\n","            counter += 1;\n","        else:\n","            break;\n","    return L;"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:17.935468Z","iopub.status.busy":"2022-10-02T11:17:17.934969Z","iopub.status.idle":"2022-10-02T11:17:21.514032Z","shell.execute_reply":"2022-10-02T11:17:21.512682Z","shell.execute_reply.started":"2022-10-02T11:17:17.935421Z"},"trusted":true},"outputs":[],"source":["movies['cast'] = movies['cast'].apply(convert1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:21.516129Z","iopub.status.busy":"2022-10-02T11:17:21.515663Z","iopub.status.idle":"2022-10-02T11:17:21.539856Z","shell.execute_reply":"2022-10-02T11:17:21.538291Z","shell.execute_reply.started":"2022-10-02T11:17:21.516084Z"},"trusted":true},"outputs":[],"source":["movies.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:21.542315Z","iopub.status.busy":"2022-10-02T11:17:21.541528Z","iopub.status.idle":"2022-10-02T11:17:21.550254Z","shell.execute_reply":"2022-10-02T11:17:21.549335Z","shell.execute_reply.started":"2022-10-02T11:17:21.542266Z"},"trusted":true},"outputs":[],"source":["# Extracting the director name from within the crew\n","def extract_director(obj):\n","    L = []\n","    for i in ast.literal_eval(obj):\n","        if i[\"job\"] == \"Director\":\n","            L.append(i[\"name\"])\n","            break;\n","    return L;"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:21.552150Z","iopub.status.busy":"2022-10-02T11:17:21.551639Z","iopub.status.idle":"2022-10-02T11:17:25.444002Z","shell.execute_reply":"2022-10-02T11:17:25.442824Z","shell.execute_reply.started":"2022-10-02T11:17:21.552118Z"},"trusted":true},"outputs":[],"source":["movies['crew'] = movies['crew'].apply(extract_director)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:25.446085Z","iopub.status.busy":"2022-10-02T11:17:25.445732Z","iopub.status.idle":"2022-10-02T11:17:25.467081Z","shell.execute_reply":"2022-10-02T11:17:25.465790Z","shell.execute_reply.started":"2022-10-02T11:17:25.446051Z"},"trusted":true},"outputs":[],"source":["movies.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:25.469653Z","iopub.status.busy":"2022-10-02T11:17:25.469061Z","iopub.status.idle":"2022-10-02T11:17:25.511980Z","shell.execute_reply":"2022-10-02T11:17:25.510875Z","shell.execute_reply.started":"2022-10-02T11:17:25.469583Z"},"trusted":true},"outputs":[],"source":["movies['overview'] = movies['overview'].apply(lambda x : x.split())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:25.513954Z","iopub.status.busy":"2022-10-02T11:17:25.513466Z","iopub.status.idle":"2022-10-02T11:17:25.540193Z","shell.execute_reply":"2022-10-02T11:17:25.538820Z","shell.execute_reply.started":"2022-10-02T11:17:25.513910Z"},"trusted":true},"outputs":[],"source":["movies.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We have finally preprocessed `genres`, `cast`, `overview`, and `crew` and converted them into lists. This brings **step 2** to a close."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a name=\"1.3.3\"></a>\n","#### Step 3: Building a new dataframe from the dataframe above\n","Step 3 will be to concatenate these lists from each row into single lists and then convert each of those single lists into single strings. The column for all those strings will be `tags`.\n","\n","\n","*For recommender systems, having spaces within a name or words to describe a single thing (such as a genre name) could create some issues; for instance, we might be searching for the actor named '**Christian Bale**' but we might get recommended to '**Christian Slater**'. Thus, removing the space and changing the name to 'ChristianBale' would make the recommendation better for me.*\n","\n","***I will remove spaces between words for `genres`, `cast`, `keywords`, and `crew`.***"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:25.542446Z","iopub.status.busy":"2022-10-02T11:17:25.541943Z","iopub.status.idle":"2022-10-02T11:17:25.639002Z","shell.execute_reply":"2022-10-02T11:17:25.637441Z","shell.execute_reply.started":"2022-10-02T11:17:25.542374Z"},"trusted":true},"outputs":[],"source":["movies['genres'] = movies['genres'].apply(lambda x : [i.replace(\" \", \"\") for i in x])\n","movies['cast'] = movies['cast'].apply(lambda x : [i.replace(\" \", \"\") for i in x])\n","movies['overview'] = movies['overview'].apply(lambda x : [i.replace(\" \", \"\") for i in x])\n","movies['crew'] = movies['crew'].apply(lambda x : [i.replace(\" \", \"\") for i in x])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:25.641698Z","iopub.status.busy":"2022-10-02T11:17:25.641231Z","iopub.status.idle":"2022-10-02T11:17:25.667583Z","shell.execute_reply":"2022-10-02T11:17:25.666245Z","shell.execute_reply.started":"2022-10-02T11:17:25.641661Z"},"trusted":true},"outputs":[],"source":["movies.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:25.669731Z","iopub.status.busy":"2022-10-02T11:17:25.669169Z","iopub.status.idle":"2022-10-02T11:17:25.751615Z","shell.execute_reply":"2022-10-02T11:17:25.750184Z","shell.execute_reply.started":"2022-10-02T11:17:25.669681Z"},"trusted":true},"outputs":[],"source":["# Concatenating the 5 columns into a new column 'tags'\n","movies['tags'] = movies['genres'] + movies['cast'] + movies['overview'] + movies['keywords'] + movies['crew']\n","mov_new = movies[['id', 'title', 'tags']]\n","mov_new"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:25.755126Z","iopub.status.busy":"2022-10-02T11:17:25.754655Z","iopub.status.idle":"2022-10-02T11:17:25.775837Z","shell.execute_reply":"2022-10-02T11:17:25.774239Z","shell.execute_reply.started":"2022-10-02T11:17:25.755079Z"},"trusted":true},"outputs":[],"source":["# Finally, converting the list 'tags' into a string\n","mov_new['tags'] = mov_new['tags'].apply(lambda x : \" \".join(x))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:25.778249Z","iopub.status.busy":"2022-10-02T11:17:25.777505Z","iopub.status.idle":"2022-10-02T11:17:25.792594Z","shell.execute_reply":"2022-10-02T11:17:25.791305Z","shell.execute_reply.started":"2022-10-02T11:17:25.778215Z"},"trusted":true},"outputs":[],"source":["#converting every letter into lowercase\n","mov_new['tags'] = mov_new['tags'].apply(lambda x : x.lower())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:25.794840Z","iopub.status.busy":"2022-10-02T11:17:25.794349Z","iopub.status.idle":"2022-10-02T11:17:25.805443Z","shell.execute_reply":"2022-10-02T11:17:25.803844Z","shell.execute_reply.started":"2022-10-02T11:17:25.794794Z"},"trusted":true},"outputs":[],"source":["import nltk\n","from nltk.stem.porter import PorterStemmer\n","ps = PorterStemmer()\n","#importing this library to stem all the different forms of the same words into single words"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:25.812726Z","iopub.status.busy":"2022-10-02T11:17:25.812273Z","iopub.status.idle":"2022-10-02T11:17:25.820320Z","shell.execute_reply":"2022-10-02T11:17:25.819023Z","shell.execute_reply.started":"2022-10-02T11:17:25.812687Z"},"trusted":true},"outputs":[],"source":["def stem(text):\n","    y = []\n","    for i in text.split():\n","        y.append(ps.stem(i));\n","    \n","    return \" \".join(y) #to change into a string again\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:25.823296Z","iopub.status.busy":"2022-10-02T11:17:25.822090Z","iopub.status.idle":"2022-10-02T11:17:33.817767Z","shell.execute_reply":"2022-10-02T11:17:33.815424Z","shell.execute_reply.started":"2022-10-02T11:17:25.823246Z"},"trusted":true},"outputs":[],"source":["mov_new['tags'] = mov_new['tags'].apply(stem)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:33.819706Z","iopub.status.busy":"2022-10-02T11:17:33.819294Z","iopub.status.idle":"2022-10-02T11:17:33.832862Z","shell.execute_reply":"2022-10-02T11:17:33.831576Z","shell.execute_reply.started":"2022-10-02T11:17:33.819673Z"},"trusted":true},"outputs":[],"source":["mov_new.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a name=\"2\"></a>\n","## 2. Text vectorization\n","\n","What is our objective? A user will write a name, and we want to recommend other similar 5 movies to the ones they type.\n","\n","For that, we need to calculate similarities between the texts that we have under the column `tags` and find 5 most similar movies.\n","\n","To calculate similarities between the texts, we need to calculate their similarity scores. For this, we need **text vectorization**.\n","\n","**Concept**: We convert each movie `tag` into a vector. Out of roughly 5000 movies, the 5 movie vectors that are closest to the vector of the movie that the user types will be recommended. And, the text vectorization I'll use will be **CountVectorizer** from sklearn library.\n","\n","I shall be ignoring any **stop words**. The vectorization will be done for the rest of the words. Then, I'll calculate the distance between the movie typed by the user to the other vectors and see which movies are the closest in distance."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:33.834738Z","iopub.status.busy":"2022-10-02T11:17:33.834396Z","iopub.status.idle":"2022-10-02T11:17:33.843320Z","shell.execute_reply":"2022-10-02T11:17:33.842253Z","shell.execute_reply.started":"2022-10-02T11:17:33.834706Z"},"trusted":true},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","cvec = CountVectorizer(max_features = 5000, stop_words = 'english')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:33.844917Z","iopub.status.busy":"2022-10-02T11:17:33.844436Z","iopub.status.idle":"2022-10-02T11:17:34.432217Z","shell.execute_reply":"2022-10-02T11:17:34.430866Z","shell.execute_reply.started":"2022-10-02T11:17:33.844870Z"},"trusted":true},"outputs":[],"source":["vectorization = cvec.fit_transform(mov_new['tags']).toarray()\n","vectorization"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:34.435126Z","iopub.status.busy":"2022-10-02T11:17:34.434654Z","iopub.status.idle":"2022-10-02T11:17:34.469030Z","shell.execute_reply":"2022-10-02T11:17:34.467581Z","shell.execute_reply.started":"2022-10-02T11:17:34.435081Z"},"trusted":true},"outputs":[],"source":["cvec.get_feature_names()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We will not use **`Euclidean distance`**. Instead, we will calculate the **`Cosine distance`**, i.e., the angle between vectors."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:34.472097Z","iopub.status.busy":"2022-10-02T11:17:34.471560Z","iopub.status.idle":"2022-10-02T11:17:34.478844Z","shell.execute_reply":"2022-10-02T11:17:34.477301Z","shell.execute_reply.started":"2022-10-02T11:17:34.472047Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics.pairwise import cosine_similarity"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:17:34.481904Z","iopub.status.busy":"2022-10-02T11:17:34.481329Z","iopub.status.idle":"2022-10-02T11:17:36.934795Z","shell.execute_reply":"2022-10-02T11:17:36.933090Z","shell.execute_reply.started":"2022-10-02T11:17:34.481840Z"},"trusted":true},"outputs":[],"source":["similarity = cosine_similarity(vectorization) #calculating distance between the vectors"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a name=\"3\"></a>\n","## 3. Creating the Main Function for Recommendation\n","\n","We create the main function that will be our workhorse to fetch index of each movie from the dataset, sort the movies from highest to lowest similarity scores, and pick out 5 movies that are the most similar to the movie that gets entered by the user."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:20:53.720102Z","iopub.status.busy":"2022-10-02T11:20:53.719674Z","iopub.status.idle":"2022-10-02T11:20:53.727081Z","shell.execute_reply":"2022-10-02T11:20:53.725713Z","shell.execute_reply.started":"2022-10-02T11:20:53.720066Z"},"trusted":true},"outputs":[],"source":["#fetching the index of each movie from the dataset\n","def recommend(movie):\n","    movie_index = mov_new[mov_new['title'] == movie].index[0]\n","    distance = similarity[movie_index]\n","    \n","    # sorting the movies from highest similarity scores to lowest similarity scores while preserving their indexes\n","    # and then picking out 5 movies that are the most similar\n","    movie_list = sorted(list(enumerate(distance)), reverse = True, key = lambda x : x[1])[1:6]\n","    \n","    for i in movie_list:\n","        print(mov_new.iloc[i[0]].title)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:23:37.202196Z","iopub.status.busy":"2022-10-02T11:23:37.201776Z","iopub.status.idle":"2022-10-02T11:23:37.215414Z","shell.execute_reply":"2022-10-02T11:23:37.214089Z","shell.execute_reply.started":"2022-10-02T11:23:37.202163Z"},"trusted":true},"outputs":[],"source":["#Checking the recommendation with different movies\n","recommend('The Dark Knight')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:23:03.417926Z","iopub.status.busy":"2022-10-02T11:23:03.417183Z","iopub.status.idle":"2022-10-02T11:23:03.431174Z","shell.execute_reply":"2022-10-02T11:23:03.429740Z","shell.execute_reply.started":"2022-10-02T11:23:03.417886Z"},"trusted":true},"outputs":[],"source":["recommend('John Carter')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T11:23:00.825325Z","iopub.status.busy":"2022-10-02T11:23:00.824578Z","iopub.status.idle":"2022-10-02T11:23:00.838295Z","shell.execute_reply":"2022-10-02T11:23:00.836709Z","shell.execute_reply.started":"2022-10-02T11:23:00.825278Z"},"trusted":true},"outputs":[],"source":["recommend('The Mummy Returns')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-02T12:25:22.669157Z","iopub.status.busy":"2022-10-02T12:25:22.668697Z","iopub.status.idle":"2022-10-02T12:25:23.569531Z","shell.execute_reply":"2022-10-02T12:25:23.567949Z","shell.execute_reply.started":"2022-10-02T12:25:22.669123Z"},"trusted":true},"outputs":[],"source":["# using pickle to save our data\n","import pickle\n","pickle.dump(mov_new.to_dict(), open('movies_dict.pkl', 'wb'))\n","pickle.dump(similarity, open('similarity.pkl', 'wb'))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a name=\"4\"></a>\n","## 4. Streamlit and Deployment\n","\n","I have used Pycharm for the steps from here. I used the movie database API with my API key to get the json of each movie and extracted the poster path via there.\n","\n","The Streamlit code is pasted below:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import streamlit as st\n","import pickle\n","import pandas as pd\n","import requests\n","\n","def get_poster(movie_id):\n","    response = requests.get(\"https://api.themoviedb.org/3/movie/{}?api_key={api_key_here}\".format(movie_id))\n","    data = response.json()\n","    return \"https://image.tmdb.org/t/p/w500/\" + data['poster_path']\n","\n","def recommend(movie):\n","    movie_index = movies[movies['title'] == movie].index[0]\n","    distance = similarity[movie_index]\n","    movie_list = sorted(list(enumerate(distance)), reverse = True, key = lambda x : x[1])[1:6]\n","\n","    recommended_movies = []\n","    recommended_mov_posters = []\n","    for i in movie_list:\n","        movie_id = movies.iloc[i[0]].id;\n","        #we'll get posters here via API\n","        recommended_movies.append(movies.iloc[i[0]].title)\n","        recommended_mov_posters.append(get_poster(movie_id))\n","    return recommended_movies, recommended_mov_posters;\n","\n","movie_list = pickle.load(open('movies_dict.pkl', 'rb'))\n","movies = pd.DataFrame(movie_list)\n","\n","similarity = pickle.load(open('similarity.pkl', 'rb'))\n","\n","st.title('Movie Recommender System')\n","\n","movie_picked = st.selectbox(\n","'Pick a movie. We will recommend 5 movies from our library that are the most similar to it.', movies['title'].values)\n","\n","if st.button('Recommend'):\n","    names, posters = recommend(movie_picked)\n","    col1, col2, col3, col4, col5 = st.columns(5)\n","\n","    with col1:\n","        st.text(names[0])\n","        st.image(posters[0])\n","\n","    with col2:\n","        st.text(names[1])\n","        st.image(posters[1])\n","\n","    with col3:\n","        st.text(names[2])\n","        st.image(posters[2])\n","\n","    with col4:\n","        st.text(names[3])\n","        st.image(posters[3])\n","\n","    with col5:\n","        st.text(names[4])\n","        st.image(posters[4])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The streamlit code can also be accessed in Github [via this link](https://github.com/psumitcode/movie-recommender-system/blob/main/recommender_app.py).\n","\n","In addition to the code above, I had created 4 other files: `Procfile`, `setup.sh`, `.gitignore`, and `requirements.txt` for deployment. `Procfile` is used by the website [Heroku](http://www.heroku.com/) to help its users build cloud-based applications. \n","\n","> I had originally used the Heroku platform for hosting; however, since it doesn't have free services anymore, I migrated the app to [Render](https://render.com/).\n","\n","The link to the recommender app developed with these codes can be accessed [HERE](https://cine-recs.com/). It's a custom domain that I've made use of via `Route 53`, the DNS provider by AWS (`A` and `CNAME` records in use).\n","\n","These files have been uploaded to the [GitHub repository](https://github.com/psumitcode/movie-recommender-system) along with this notebook."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
